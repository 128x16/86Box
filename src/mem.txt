Comparing files mem.c and MEM_NEW.C
***** mem.c


***** MEM_NEW.C

uint64_t                *byte_dirty_mask;
uint64_t                *byte_code_present_mask;

uint32_t                purgable_page_list_head = 0;
int                     purgeable_page_count = 0;


*****

***** mem.c

#ifdef USE_DYNAREC
    if (pages[phys >> 12].block[0] || pages[phys >> 12].block[1] || pages[phys >> 12].block[2] || pages[phys >> 12].block[3] ||
 (phys & ~0xfff) == recomp_page)
#else
    if (pages[phys >> 12].block[0] || pages[phys >> 12].block[1] || pages[phys >> 12].block[2] || pages[phys >> 12].block[3])
#endif
        page_lookup[virt >> 12] = &pages[phys >> 12];
      else
        writelookup2[virt>>12] = (uintptr_t)&ram[(uintptr_t)(phys & ~0xFFF) - (uintptr_t)(virt & ~0xfff)];
***** MEM_NEW.C

    if (pages[phys >> 12].block || (phys & ~0xfff) == recomp_page)
        page_lookup[virt >> 12] = &pages[phys >> 12];//(uintptr_t)&ram[(uintptr_t)(phys & ~0xFFF) - (uintptr_t)(virt & ~0xfff)]
;
    else
        writelookup2[virt>>12] = (uintptr_t)&ram[(uintptr_t)(phys & ~0xFFF) - (uintptr_t)(virt & ~0xfff)];
*****

***** mem.c
        page_lookup[addr>>12]->write_b(addr, val, page_lookup[addr>>12]);

        return;
***** MEM_NEW.C
        page_lookup[addr>>12]->write_b(addr, val, page_lookup[addr>>12]);
        return;
*****

***** mem.c
        addr = mmutranslate_write(addr);
        if (addr == 0xffffffff)
                return;
***** MEM_NEW.C
        addr = mmutranslate_write(addr);
        if (addr == 0xFFFFFFFF)
                return;
*****

***** mem.c
    if (map && map->write_b)
        map->write_b(addr, val, map->p);
}
***** MEM_NEW.C
    if (map && map->write_b)
        return map->write_b(addr, val, map->p);
}
*****

***** mem.c

uint8_t
readmemb386l(uint32_t seg, uint32_t addr)
{
    return readmembl(addr + seg);
}


void
writememb386l(uint32_t seg, uint32_t addr, uint8_t val)
{
    writemembl(addr + seg, val);
}


***** MEM_NEW.C


*****

***** mem.c
uint16_t
readmemwl(uint32_t seg, uint32_t addr)
{
***** MEM_NEW.C
uint16_t
readmemwl(uint32_t addr)
{
*****

***** mem.c
    mem_mapping_t *map;
    uint32_t addr2 = mem_logical_addr = seg + addr;

    if (addr2 & 1) {
        if (!cpu_cyrix_alignment || (addr2 & 7) == 7)
                sub_cycles(timing_misaligned);
        if ((addr2 & 0xFFF) > 0xffe) {
                if (cr0 >> 31) {
                        if (mmutranslate_read(addr2)   == 0xffffffff) return 0xffff;
                        if (mmutranslate_read(addr2+1) == 0xffffffff) return 0xffff;
                }
                if (is386) return readmemb386l(seg,addr)|(((uint16_t) readmemb386l(seg,addr+1))<<8);
                else       return readmembl(seg+addr)|(((uint16_t) readmembl(seg+addr+1))<<8);
        }
        else if (readlookup2[addr2 >> 12] != (uintptr_t) -1)
                return *(uint16_t *)(readlookup2[addr2 >> 12] + addr2);
    }

    if (cr0 >> 31) {
        addr2 = mmutranslate_read(addr2);
        if (addr2 == 0xffffffff)
                return 0xFFFF;
***** MEM_NEW.C
    mem_mapping_t *map;

    mem_logical_addr = addr;

    if (addr & 1) {
        if (!cpu_cyrix_alignment || (addr & 7) == 7)
                sub_cycles(timing_misaligned);
        if ((addr & 0xFFF) > 0xFFE) {
                if (cr0 >> 31) {
                        if (mmutranslate_read(addr)   == 0xffffffff)
                                return 0xffff;
                        if (mmutranslate_read(addr+1) == 0xffffffff)
                                return 0xffff;
                }
                return readmembl(addr)|(readmembl(addr+1)<<8);
        } else if (readlookup2[addr >> 12] != -1)
                return *(uint16_t *)(readlookup2[addr >> 12] + addr);
    }
    if (cr0>>31) {
        addr = mmutranslate_read(addr);
        if (addr==0xFFFFFFFF)
                return 0xFFFF;
*****

***** mem.c

    addr2 &= rammask;

    map = read_mapping[addr2 >> MEM_GRANULARITY_BITS];

    if (map && map->read_w)
        return map->read_w(addr2, map->p);

    if (map && map->read_b) {
        if (AT)
                return map->read_b(addr2, map->p) |
                       ((uint16_t) (map->read_b(addr2 + 1, map->p)) << 8);
        else
                return map->read_b(addr2, map->p) |
                       ((uint16_t) (map->read_b(seg + ((addr + 1) & 0xffff), map->p)) << 8);
    }
***** MEM_NEW.C

    addr &= rammask;

    map = read_mapping[addr >> MEM_GRANULARITY_BITS];
    if (map) {
        if (map->read_w)
                return map->read_w(addr, map->p);

        if (map->read_b)
                return map->read_b(addr, map->p) | (map->read_b(addr + 1, map->p) << 8);
    }
*****

***** mem.c
void
writememwl(uint32_t seg, uint32_t addr, uint16_t val)
{
***** MEM_NEW.C
void
writememwl(uint32_t addr, uint16_t val)
{
*****

***** mem.c
    mem_mapping_t *map;
    uint32_t addr2 = mem_logical_addr = seg + addr;

    if (addr2 & 1) {
        if (!cpu_cyrix_alignment || (addr2 & 7) == 7)
                sub_cycles(timing_misaligned);
        if ((addr2 & 0xFFF) > 0xffe) {
                if (cr0 >> 31) {
                        if (mmutranslate_write(addr2)   == 0xffffffff) return;
                        if (mmutranslate_write(addr2+1) == 0xffffffff) return;
                }
                if (is386) {
                        writememb386l(seg,addr,val);
                        writememb386l(seg,addr+1,val>>8);
                } else {
                        writemembl(seg+addr,val);
                        writemembl(seg+addr+1,val>>8);
                }
                return;
        } else if (writelookup2[addr2 >> 12] != (uintptr_t) -1) {
                *(uint16_t *)(writelookup2[addr2 >> 12] + addr2) = val;
                return;
***** MEM_NEW.C
    mem_mapping_t *map;

    mem_logical_addr = addr;

    if (addr & 1) {
        if (!cpu_cyrix_alignment || (addr & 7) == 7)
                sub_cycles(timing_misaligned);
        if ((addr & 0xFFF) > 0xFFE) {
                if (cr0 >> 31) {
                        if (mmutranslate_write(addr)   == 0xffffffff)
                                return;
                        if (mmutranslate_write(addr+1) == 0xffffffff)
                                return;
                }
                writemembl(addr,val);
                writemembl(addr+1,val>>8);
                return;
        } else if (writelookup2[addr >> 12] != -1) {
                *(uint16_t *)(writelookup2[addr >> 12] + addr) = val;
                return;
*****

***** mem.c

    if (page_lookup[addr2>>12]) {
        page_lookup[addr2>>12]->write_w(addr2, val, page_lookup[addr2>>12]);
        return;
***** MEM_NEW.C

    if (page_lookup[addr>>12]) {
        page_lookup[addr>>12]->write_w(addr, val, page_lookup[addr>>12]);
        return;
*****

***** mem.c
    }

    if (cr0 >> 31) {
        addr2 = mmutranslate_write(addr2);
        if (addr2 == 0xffffffff) return;
    }
***** MEM_NEW.C
    }
    if (cr0>>31) {
        addr = mmutranslate_write(addr);
        if (addr==0xFFFFFFFF)
                return;
    }
*****

***** mem.c

    addr2 &= rammask;

    map = write_mapping[addr2 >> MEM_GRANULARITY_BITS];

    if (map && map->write_w) {
        map->write_w(addr2, val, map->p);
        return;
    }

    if (map && map->write_b) {
        map->write_b(addr2, val, map->p);
        map->write_b(addr2 + 1, val >> 8, map->p);
        return;
    }
***** MEM_NEW.C

    addr &= rammask;

    map = write_mapping[addr >> MEM_GRANULARITY_BITS];
    if (map) {
        if (map->write_w)
                map->write_w(addr, val, map->p);
        else if (map->write_b) {
                map->write_b(addr, val, map->p);
                map->write_b(addr + 1, val >> 8, map->p);
        }
    }
*****

***** mem.c
uint32_t
readmemll(uint32_t seg, uint32_t addr)
{
***** MEM_NEW.C
uint32_t
readmemll(uint32_t addr)
{
*****

***** mem.c
    mem_mapping_t *map;
    uint32_t addr2 = mem_logical_addr = seg + addr;

    if (addr2 & 3) {
        if (!cpu_cyrix_alignment || (addr2 & 7) > 4)
                sub_cycles(timing_misaligned);
        if ((addr2 & 0xfff) > 0xffc) {
                if (cr0 >> 31) {
                        if (mmutranslate_read(addr2)   == 0xffffffff) return 0xffffffff;
                        if (mmutranslate_read(addr2+3) == 0xffffffff) return 0xffffffff;
                }
                return readmemwl(seg,addr)|(readmemwl(seg,addr+2)<<16);
        } else if (readlookup2[addr2 >> 12] != (uintptr_t) -1)
                return *(uint32_t *)(readlookup2[addr2 >> 12] + addr2);
    }
***** MEM_NEW.C
    mem_mapping_t *map;

    mem_logical_addr = addr;

    if (addr & 3) {
        if (!cpu_cyrix_alignment || (addr & 7) > 4)
                sub_cycles(timing_misaligned);
        if ((addr&0xFFF)>0xFFC) {
                if (cr0>>31) {
                        if (mmutranslate_read(addr)   == 0xffffffff)
                                return 0xffffffff;
                        if (mmutranslate_read(addr+3) == 0xffffffff)
                                return 0xffffffff;
                }
                return readmemwl(addr)|(readmemwl(addr+2)<<16);
        } else if (readlookup2[addr >> 12] != -1)
                return *(uint32_t *)(readlookup2[addr >> 12] + addr);
    }
*****

***** mem.c

    if (cr0 >> 31) {
        addr2 = mmutranslate_read(addr2);
        if (addr2 == 0xffffffff)
                return 0xffffffff;
    }
***** MEM_NEW.C

    if (cr0>>31) {
        addr = mmutranslate_read(addr);
        if (addr==0xFFFFFFFF)
                return 0xFFFFFFFF;
    }
*****

***** mem.c

    addr2 &= rammask;

    map = read_mapping[addr2 >> MEM_GRANULARITY_BITS];

    if (map && map->read_l)
        return map->read_l(addr2, map->p);

    if (map && map->read_w)
        return map->read_w(addr2, map->p) |
               ((uint32_t) (map->read_w(addr2 + 2, map->p)) << 16);

    if (map && map->read_b)
        return map->read_b(addr2, map->p) |
               ((uint32_t) (map->read_b(addr2 + 1, map->p)) << 8) |
               ((uint32_t) (map->read_b(addr2 + 2, map->p)) << 16) |
               ((uint32_t) (map->read_b(addr2 + 3, map->p)) << 24);

***** MEM_NEW.C

    addr&=rammask;

    map = read_mapping[addr >> MEM_GRANULARITY_BITS];
    if (map) {
        if (map->read_l)
                return map->read_l(addr, map->p);

        if (map->read_w)
                return map->read_w(addr, map->p) | (map->read_w(addr + 2, map->p) << 16);

        if (map->read_b)
                return map->read_b(addr, map->p) | (map->read_b(addr + 1, map->p) << 8) |
                       (map->read_b(addr + 2, map->p) << 16) | (map->read_b(addr + 3, map->p) << 24);
    }

*****

***** mem.c
void
writememll(uint32_t seg, uint32_t addr, uint32_t val)
{
***** MEM_NEW.C
void
writememll(uint32_t addr, uint32_t val)
{
*****

***** mem.c
    mem_mapping_t *map;
    uint32_t addr2 = mem_logical_addr = seg + addr;

    if (addr2 & 3) {
        if (!cpu_cyrix_alignment || (addr2 & 7) > 4)
                sub_cycles(timing_misaligned);
        if ((addr2 & 0xfff) > 0xffc) {
                if (cr0 >> 31) {
                        if (mmutranslate_write(addr2)   == 0xffffffff) return;
                        if (mmutranslate_write(addr2+3) == 0xffffffff) return;
                }
                writememwl(seg,addr,val);
                writememwl(seg,addr+2,val>>16);
                return;
        } else if (writelookup2[addr2 >> 12] != (uintptr_t) -1) {
                *(uint32_t *)(writelookup2[addr2 >> 12] + addr2) = val;
                return;
***** MEM_NEW.C
    mem_mapping_t *map;

    mem_logical_addr = addr;

    if (addr & 3) {
        if (!cpu_cyrix_alignment || (addr & 7) > 4)
                sub_cycles(timing_misaligned);
        if ((addr & 0xFFF) > 0xFFC) {
                if (cr0>>31) {
                        if (mmutranslate_write(addr)   == 0xffffffff)
                                return;
                        if (mmutranslate_write(addr+3) == 0xffffffff)
                                return;
                }
                writememwl(addr,val);
                writememwl(addr+2,val>>16);
                return;
        } else if (writelookup2[addr >> 12] != -1) {
                *(uint32_t *)(writelookup2[addr >> 12] + addr) = val;
                return;
*****

***** mem.c
    }

    if (page_lookup[addr2>>12]) {
        page_lookup[addr2>>12]->write_l(addr2, val, page_lookup[addr2>>12]);
        return;
***** MEM_NEW.C
    }
    if (page_lookup[addr>>12]) {
        page_lookup[addr>>12]->write_l(addr, val, page_lookup[addr>>12]);
        return;
*****

***** mem.c
    }

    if (cr0 >> 31) {
        addr2 = mmutranslate_write(addr2);
        if (addr2 == 0xffffffff) return;
    }
***** MEM_NEW.C
    }
    if (cr0>>31) {
        addr = mmutranslate_write(addr);
        if (addr==0xFFFFFFFF)
                return;
    }
*****

***** mem.c

    addr2 &= rammask;

    map = write_mapping[addr2 >> MEM_GRANULARITY_BITS];

    if (map && map->write_l) {
        map->write_l(addr2, val,           map->p);
        return;
    }
    if (map && map->write_w) {
        map->write_w(addr2,     val,       map->p);
        map->write_w(addr2 + 2, val >> 16, map->p);
        return;
    }
    if (map && map->write_b) {
        map->write_b(addr2,     val,       map->p);
        map->write_b(addr2 + 1, val >> 8,  map->p);
        map->write_b(addr2 + 2, val >> 16, map->p);
        map->write_b(addr2 + 3, val >> 24, map->p);
        return;
    }
***** MEM_NEW.C

    addr&=rammask;

    map = write_mapping[addr >> MEM_GRANULARITY_BITS];
    if (map) {
        if (map->write_l)
                map->write_l(addr, val, map->p);
        else if (map->write_w) {
                map->write_w(addr, val, map->p);
                map->write_w(addr + 2, val >> 16, map->p);
        } else if (map->write_b) {
                map->write_b(addr, val, map->p);
                map->write_b(addr + 1, val >> 8, map->p);
                map->write_b(addr + 2, val >> 16, map->p);
                map->write_b(addr + 3, val >> 24, map->p);
        }
    }
*****

***** mem.c
uint64_t
readmemql(uint32_t seg, uint32_t addr)
{
***** MEM_NEW.C
uint64_t
readmemql(uint32_t addr)
{
*****

***** mem.c
    mem_mapping_t *map;
    uint32_t addr2 = mem_logical_addr = seg + addr;

    if (addr2 & 7) {
        sub_cycles(timing_misaligned);
        if ((addr2 & 0xfff) > 0xff8) {
                if (cr0 >> 31) {
                        if (mmutranslate_read(addr2)   == 0xffffffff) return 0xffffffff;
                        if (mmutranslate_read(addr2+7) == 0xffffffff) return 0xffffffff;
                }
                return readmemll(seg,addr)|((uint64_t)readmemll(seg,addr+4)<<32);
        } else if (readlookup2[addr2 >> 12] != (uintptr_t) -1)
                return *(uint64_t *)(readlookup2[addr2 >> 12] + addr2);
    }
***** MEM_NEW.C
    mem_mapping_t *map;

    mem_logical_addr = addr;

    if (addr & 7) {
        sub_cycles(timing_misaligned);
        if ((addr & 0xFFF) > 0xFF8) {
                if (cr0>>31) {
                        if (mmutranslate_read(addr)   == 0xffffffff)
                                return 0xffffffff;
                        if (mmutranslate_read(addr+7) == 0xffffffff)
                                return 0xffffffff;
                }
                return readmemll(addr)|((uint64_t)readmemll(addr+4)<<32);
        } else if (readlookup2[addr >> 12] != -1)
                return *(uint64_t *)(readlookup2[addr >> 12] + addr);
    }
*****

***** mem.c

    if (cr0 >> 31) {
        addr2 = mmutranslate_read(addr2);
        if (addr2 == 0xffffffff)
                return -1;
    }
***** MEM_NEW.C

    if (cr0>>31) {
        addr = mmutranslate_read(addr);
        if (addr==0xFFFFFFFF)
                return 0xFFFFFFFF;
    }
*****

***** mem.c

    addr2 &= rammask;

    map = read_mapping[addr2 >> MEM_GRANULARITY_BITS];
    if (map && map->read_l)
        return map->read_l(addr2, map->p) | ((uint64_t)map->read_l(addr2 + 4, map->p) << 32);

    return readmemll(seg,addr) | ((uint64_t)readmemll(seg,addr+4)<<32);
}
***** MEM_NEW.C

    addr&=rammask;

    map = read_mapping[addr >> MEM_GRANULARITY_BITS];
    if (map && map->read_l)
        return map->read_l(addr, map->p) | ((uint64_t)map->read_l(addr + 4, map->p) << 32);

    return readmemll(addr) | ((uint64_t)readmemll(addr+4)<<32);
}
*****

***** mem.c
void
writememql(uint32_t seg, uint32_t addr, uint64_t val)
{
***** MEM_NEW.C
void
writememql(uint32_t addr, uint64_t val)
{
*****

***** mem.c
    mem_mapping_t *map;
    uint32_t addr2 = mem_logical_addr = seg + addr;

    if (addr2 & 7) {
        sub_cycles(timing_misaligned);
        if ((addr2 & 0xfff) > 0xff8) {
                if (cr0 >> 31) {
                        if (mmutranslate_write(addr2)   == 0xffffffff) return;
                        if (mmutranslate_write(addr2+7) == 0xffffffff) return;
                }
                writememll(seg, addr, val);
                writememll(seg, addr+4, val >> 32);
                return;
        } else if (writelookup2[addr2 >> 12] != (uintptr_t) -1) {
                *(uint64_t *)(writelookup2[addr2 >> 12] + addr2) = val;
                return;
***** MEM_NEW.C
    mem_mapping_t *map;

    mem_logical_addr = addr;

    if (addr & 7) {
        sub_cycles(timing_misaligned);
        if ((addr & 0xFFF) > 0xFF8) {
                if (cr0>>31) {
                        if (mmutranslate_write(addr)   == 0xffffffff)
                                return;
                        if (mmutranslate_write(addr+7) == 0xffffffff)
                                return;
                }
                writememll(addr, val);
                writememll(addr+4, val >> 32);
                return;
        } else if (writelookup2[addr >> 12] != -1) {
                *(uint64_t *)(writelookup2[addr >> 12] + addr) = val;
                return;
*****

***** mem.c
    }

    if (page_lookup[addr2>>12]) {
        page_lookup[addr2>>12]->write_l(addr2, val, page_lookup[addr2>>12]);
        page_lookup[addr2>>12]->write_l(addr2 + 4, val >> 32, page_lookup[addr2>>12]);
        return;
***** MEM_NEW.C
    }
    if (page_lookup[addr>>12]) {
        page_lookup[addr>>12]->write_l(addr, val, page_lookup[addr>>12]);
        page_lookup[addr>>12]->write_l(addr + 4, val >> 32, page_lookup[addr>>12]);
        return;
*****

***** mem.c
    }

    if (cr0 >> 31) {
        addr2 = mmutranslate_write(addr2);
        if (addr2 == 0xffffffff) return;
    }
***** MEM_NEW.C
    }
    if (cr0>>31) {
        addr = mmutranslate_write(addr);
        if (addr==0xFFFFFFFF)
                return;
    }
*****

***** mem.c

    addr2 &= rammask;

    map = write_mapping[addr2 >> MEM_GRANULARITY_BITS];

    if (map && map->write_l) {
        map->write_l(addr2,   val,       map->p);
        map->write_l(addr2+4, val >> 32, map->p);
        return;
    }
    if (map && map->write_w) {
        map->write_w(addr2,     val,       map->p);
        map->write_w(addr2 + 2, val >> 16, map->p);
        map->write_w(addr2 + 4, val >> 32, map->p);
        map->write_w(addr2 + 6, val >> 48, map->p);
        return;
    }
    if (map && map->write_b) {
        map->write_b(addr2,     val,       map->p);
        map->write_b(addr2 + 1, val >> 8,  map->p);
        map->write_b(addr2 + 2, val >> 16, map->p);
        map->write_b(addr2 + 3, val >> 24, map->p);
        map->write_b(addr2 + 4, val >> 32, map->p);
        map->write_b(addr2 + 5, val >> 40, map->p);
        map->write_b(addr2 + 6, val >> 48, map->p);
        map->write_b(addr2 + 7, val >> 56, map->p);
        return;
    }
***** MEM_NEW.C

    addr&=rammask;

    map = write_mapping[addr >> MEM_GRANULARITY_BITS];
    if (map) {
        if (map->write_l) {
                map->write_l(addr, val, map->p);
                map->write_l(addr + 4, val >> 32, map->p);
        } else if (map->write_w) {
                map->write_w(addr, val, map->p);
                map->write_w(addr + 2, val >> 16, map->p);
                map->write_w(addr + 4, val >> 32, map->p);
                map->write_w(addr + 6, val >> 48, map->p);
        } else if (map->write_b) {
                map->write_b(addr, val, map->p);
                map->write_b(addr + 1, val >> 8, map->p);
                map->write_b(addr + 2, val >> 16, map->p);
                map->write_b(addr + 3, val >> 24, map->p);
                map->write_b(addr + 4, val >> 32, map->p);
                map->write_b(addr + 5, val >> 40, map->p);
                map->write_b(addr + 6, val >> 48, map->p);
                map->write_b(addr + 7, val >> 56, map->p);
        }
    }
*****

***** mem.c

void
***** MEM_NEW.C


void
*****

***** mem.c

void
mem_write_ramb_page(uint32_t addr, uint8_t val, page_t *p)
{
#ifdef USE_DYNAREC
    if (val != p->mem[addr & 0xfff] || codegen_in_recompile) {
#else
    if (val != p->mem[addr & 0xfff]) {
#endif
        uint64_t mask = (uint64_t)1 << ((addr >> PAGE_MASK_SHIFT) & PAGE_MASK_MASK);
        p->dirty_mask[(addr >> PAGE_MASK_INDEX_SHIFT) & PAGE_MASK_INDEX_MASK] |= mask;
        p->mem[addr & 0xfff] = val;
    }
}
***** MEM_NEW.C

static inline int
page_index(page_t *p)
{
    return ((uintptr_t)p - (uintptr_t)pages) / sizeof(page_t);
}
*****

***** mem.c
void
mem_write_ramw_page(uint32_t addr, uint16_t val, page_t *p)
{
#ifdef USE_DYNAREC
    if (val != *(uint16_t *)&p->mem[addr & 0xfff] || codegen_in_recompile) {
#else
    if (val != *(uint16_t *)&p->mem[addr & 0xfff]) {
#endif
        uint64_t mask = (uint64_t)1 << ((addr >> PAGE_MASK_SHIFT) & PAGE_MASK_MASK);
        if ((addr & 0xf) == 0xf)
                mask |= (mask << 1);
        p->dirty_mask[(addr >> PAGE_MASK_INDEX_SHIFT) & PAGE_MASK_INDEX_MASK] |= mask;
        *(uint16_t *)&p->mem[addr & 0xfff] = val;
    }
}
***** MEM_NEW.C
void
page_add_to_evict_list(page_t *p)
{
    pages[purgable_page_list_head].evict_prev = page_index(p);
    p->evict_next = purgable_page_list_head;
    p->evict_prev = 0;
    purgable_page_list_head = pages[purgable_page_list_head].evict_prev;
    purgeable_page_count++;
}
*****

***** mem.c
void
mem_write_raml_page(uint32_t addr, uint32_t val, page_t *p)
{
#ifdef USE_DYNAREC
    if (val != *(uint32_t *)&p->mem[addr & 0xfff] || codegen_in_recompile) {
#else
    if (val != *(uint32_t *)&p->mem[addr & 0xfff]) {
#endif
        uint64_t mask = (uint64_t)1 << ((addr >> PAGE_MASK_SHIFT) & PAGE_MASK_MASK);
        if ((addr & 0xf) >= 0xd)
                mask |= (mask << 1);
        p->dirty_mask[(addr >> PAGE_MASK_INDEX_SHIFT) & PAGE_MASK_INDEX_MASK] |= mask;
        *(uint32_t *)&p->mem[addr & 0xfff] = val;
    }
}
***** MEM_NEW.C
void
page_remove_from_evict_list(page_t *p)
{
    if (!page_in_evict_list(p))
        fatal("page_remove_from_evict_list: not in evict list!\n");
    if (p->evict_prev)
        pages[p->evict_prev].evict_next = p->evict_next;
    else
        purgable_page_list_head = p->evict_next;
    if (p->evict_next)
        pages[p->evict_next].evict_prev = p->evict_prev;
    p->evict_prev = EVICT_NOT_IN_LIST;
        purgeable_page_count--;
}
*****

***** mem.c
void
mem_write_ram(uint32_t addr, uint8_t val, void *priv)
{
    addwritelookup(mem_logical_addr, addr);
    mem_write_ramb_page(addr, val, &pages[addr >> 12]);
}
***** MEM_NEW.C
void
mem_write_ramb_page(uint32_t addr, uint8_t val, page_t *p)
{
    if (val != p->mem[addr & 0xfff] || codegen_in_recompile) {
        uint64_t mask = (uint64_t)1 << ((addr >> PAGE_MASK_SHIFT) & PAGE_MASK_MASK);
        int byte_offset = (addr >> PAGE_BYTE_MASK_SHIFT) & PAGE_BYTE_MASK_OFFSET_MASK;
        uint64_t byte_mask = (uint64_t)1 << (addr & PAGE_BYTE_MASK_MASK);

        p->mem[addr & 0xfff] = val;
        p->dirty_mask |= mask;
        if ((p->code_present_mask & mask) && !page_in_evict_list(p))
                page_add_to_evict_list(p);
        p->byte_dirty_mask[byte_offset] |= byte_mask;
        if ((p->byte_code_present_mask[byte_offset] & byte_mask) && !page_in_evict_list(p))
                page_add_to_evict_list(p);
    }
}
*****

***** mem.c
void
mem_write_ramw(uint32_t addr, uint16_t val, void *priv)
{
    addwritelookup(mem_logical_addr, addr);
    mem_write_ramw_page(addr, val, &pages[addr >> 12]);
}
***** MEM_NEW.C
void
mem_write_ramw_page(uint32_t addr, uint16_t val, page_t *p)
{
    if (val != *(uint16_t *)&p->mem[addr & 0xfff] || codegen_in_recompile) {
        uint64_t mask = (uint64_t)1 << ((addr >> PAGE_MASK_SHIFT) & PAGE_MASK_MASK);
        int byte_offset = (addr >> PAGE_BYTE_MASK_SHIFT) & PAGE_BYTE_MASK_OFFSET_MASK;
        uint64_t byte_mask = (uint64_t)1 << (addr & PAGE_BYTE_MASK_MASK);

        if ((addr & 0xf) == 0xf)
                mask |= (mask << 1);
        *(uint16_t *)&p->mem[addr & 0xfff] = val;
        p->dirty_mask |= mask;
        if ((p->code_present_mask & mask) && !page_in_evict_list(p))
                page_add_to_evict_list(p);
        if ((addr & PAGE_BYTE_MASK_MASK) == PAGE_BYTE_MASK_MASK) {
                p->byte_dirty_mask[byte_offset+1] |= 1;
                if ((p->byte_code_present_mask[byte_offset+1] & 1) && !page_in_evict_list(p))
                        page_add_to_evict_list(p);
        } else
                byte_mask |= (byte_mask << 1);

        p->byte_dirty_mask[byte_offset] |= byte_mask;

        if ((p->byte_code_present_mask[byte_offset] & byte_mask) && !page_in_evict_list(p))
                page_add_to_evict_list(p);
    }
}
*****

***** mem.c
void
mem_write_raml(uint32_t addr, uint32_t val, void *priv)
{
    addwritelookup(mem_logical_addr, addr);
    mem_write_raml_page(addr, val, &pages[addr >> 12]);
}
***** MEM_NEW.C
void
mem_write_raml_page(uint32_t addr, uint32_t val, page_t *p)
{
    if (val != *(uint32_t *)&p->mem[addr & 0xfff] || codegen_in_recompile) {
        uint64_t mask = (uint64_t)1 << ((addr >> PAGE_MASK_SHIFT) & PAGE_MASK_MASK);
        int byte_offset = (addr >> PAGE_BYTE_MASK_SHIFT) & PAGE_BYTE_MASK_OFFSET_MASK;
        uint64_t byte_mask = (uint64_t)0xf << (addr & PAGE_BYTE_MASK_MASK);

        if ((addr & 0xf) >= 0xd)
                mask |= (mask << 1);
        *(uint32_t *)&p->mem[addr & 0xfff] = val;
        p->dirty_mask |= mask;
        p->byte_dirty_mask[byte_offset] |= byte_mask;
        if (!page_in_evict_list(p) && ((p->code_present_mask & mask) || (p->byte_code_present_mask[byte_offset] & byte_mask)))
                page_add_to_evict_list(p);
        if ((addr & PAGE_BYTE_MASK_MASK) > (PAGE_BYTE_MASK_MASK-3)) {
                uint32_t byte_mask_2 = 0xf >> (4 - (addr & 3));

                p->byte_dirty_mask[byte_offset+1] |= byte_mask_2;
                if ((p->byte_code_present_mask[byte_offset+1] & byte_mask_2) && !page_in_evict_list(p))
                        page_add_to_evict_list(p);
        }
    }
}
*****

***** mem.c

static uint8_t
mem_read_remapped(uint32_t addr, void *priv)
{
    if(addr >= (mem_size * 1024) && addr < ((mem_size + 384) * 1024))
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addreadlookup(mem_logical_addr, addr);
    return ram[addr];
}
***** MEM_NEW.C

void
mem_write_ram(uint32_t addr, uint8_t val, void *priv)
{
    addwritelookup(mem_logical_addr, addr);
    mem_write_ramb_page(addr, val, &pages[addr >> 12]);
}
*****

***** mem.c

static uint16_t
mem_read_remappedw(uint32_t addr, void *priv)
{
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addreadlookup(mem_logical_addr, addr);
    return *(uint16_t *)&ram[addr];
}
***** MEM_NEW.C

void
mem_write_ramw(uint32_t addr, uint16_t val, void *priv)
{
    addwritelookup(mem_logical_addr, addr);
    mem_write_ramw_page(addr, val, &pages[addr >> 12]);
}
*****

***** mem.c

static uint32_t
mem_read_remappedl(uint32_t addr, void *priv)
{
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addreadlookup(mem_logical_addr, addr);
    return *(uint32_t *)&ram[addr];
}
***** MEM_NEW.C

void
mem_write_raml(uint32_t addr, uint32_t val, void *priv)
{
    addwritelookup(mem_logical_addr, addr);
    mem_write_raml_page(addr, val, &pages[addr >> 12]);
}
*****

***** mem.c

static void
mem_write_remapped(uint32_t addr, uint8_t val, void *priv)
{
    uint32_t oldaddr = addr;
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addwritelookup(mem_logical_addr, addr);
    mem_write_ramb_page(addr, val, &pages[oldaddr >> 12]);
}
***** MEM_NEW.C

static uint8_t
mem_read_remapped(uint32_t addr, void *priv)
{
    if(addr >= (mem_size * 1024) && addr < ((mem_size + 384) * 1024))
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addreadlookup(mem_logical_addr, addr);
    return ram[addr];
}
*****

***** mem.c

static void
mem_write_remappedw(uint32_t addr, uint16_t val, void *priv)
{
    uint32_t oldaddr = addr;
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
***** MEM_NEW.C

static uint16_t
mem_read_remappedw(uint32_t addr, void *priv)
{
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
*****

***** mem.c
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addwritelookup(mem_logical_addr, addr);
    mem_write_ramw_page(addr, val, &pages[oldaddr >> 12]);
}
***** MEM_NEW.C
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addreadlookup(mem_logical_addr, addr);
    return *(uint16_t *)&ram[addr];
}
*****

***** mem.c

static void
mem_write_remappedl(uint32_t addr, uint32_t val, void *priv)
{
    uint32_t oldaddr = addr;
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
***** MEM_NEW.C

static uint32_t
mem_read_remappedl(uint32_t addr, void *priv)
{
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
*****

***** mem.c
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addwritelookup(mem_logical_addr, addr);
    mem_write_raml_page(addr, val, &pages[oldaddr >> 12]);
}
***** MEM_NEW.C
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addreadlookup(mem_logical_addr, addr);
    return *(uint32_t *)&ram[addr];
}
*****

***** mem.c

uint8_t
mem_read_bios(uint32_t addr, void *priv)
{
    uint8_t ret = 0xff;

    addr &= 0x000fffff;

    if ((addr >= biosaddr) && (addr <= (biosaddr + biosmask)))
        ret = rom[addr - biosaddr];

    return ret;
}
***** MEM_NEW.C

static void
mem_write_remapped(uint32_t addr, uint8_t val, void *priv)
{
    uint32_t oldaddr = addr;
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addwritelookup(mem_logical_addr, addr);
    mem_write_ramb_page(addr, val, &pages[oldaddr >> 12]);
}
*****

***** mem.c

uint16_t
mem_read_biosw(uint32_t addr, void *priv)
{
    uint16_t ret = 0xffff;

    addr &= 0x000fffff;

    if ((addr >= biosaddr) && (addr <= (biosaddr + biosmask)))
        ret = *(uint16_t *)&rom[addr - biosaddr];

    return ret;
}
***** MEM_NEW.C

static void
mem_write_remappedw(uint32_t addr, uint16_t val, void *priv)
{
    uint32_t oldaddr = addr;
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addwritelookup(mem_logical_addr, addr);
    mem_write_ramw_page(addr, val, &pages[oldaddr >> 12]);
}
*****

***** mem.c

uint32_t
mem_read_biosl(uint32_t addr, void *priv)
{
    uint32_t ret = 0xffffffff;

    addr &= 0x000fffff;

    if ((addr >= biosaddr) && (addr <= (biosaddr + biosmask)))
        ret = *(uint32_t *)&rom[addr - biosaddr];

    return ret;
}
***** MEM_NEW.C

static void
mem_write_remappedl(uint32_t addr, uint32_t val, void *priv)
{
    uint32_t oldaddr = addr;
    if(addr >= mem_size * 1024 && addr < ((mem_size + 384) * 1024))
        addr = 0xA0000 + (addr - (mem_size * 1024));
    addwritelookup(mem_logical_addr, addr);
    mem_write_raml_page(addr, val, &pages[oldaddr >> 12]);
}
*****

***** mem.c

void
mem_write_null(uint32_t addr, uint8_t val, void *p)
{
}
***** MEM_NEW.C

uint8_t
mem_read_bios(uint32_t addr, void *priv)
{
    uint8_t ret = 0xff;

    addr &= 0x000fffff;

    if ((addr >= biosaddr) && (addr <= (biosaddr + biosmask)))
        ret = rom[addr - biosaddr];

    return ret;
}
*****

***** mem.c

void
mem_write_nullw(uint32_t addr, uint16_t val, void *p)
{
}
***** MEM_NEW.C

uint16_t
mem_read_biosw(uint32_t addr, void *priv)
{
    uint16_t ret = 0xffff;

    addr &= 0x000fffff;

    if ((addr >= biosaddr) && (addr <= (biosaddr + biosmask)))
        ret = *(uint16_t *)&rom[addr - biosaddr];

    return ret;
}
*****

***** mem.c

void
mem_write_nulll(uint32_t addr, uint32_t val, void *p)
{
}
***** MEM_NEW.C

uint32_t
mem_read_biosl(uint32_t addr, void *priv)
{
    uint32_t ret = 0xffffffff;

    addr &= 0x000fffff;

    if ((addr >= biosaddr) && (addr <= (biosaddr + biosmask)))
        ret = *(uint32_t *)&rom[addr - biosaddr];

    return ret;
}
*****

***** mem.c
void
mem_invalidate_range(uint32_t start_addr, uint32_t end_addr)
{
    uint32_t cur_addr;
    start_addr &= ~PAGE_MASK_MASK;
    end_addr = (end_addr + PAGE_MASK_MASK) & ~PAGE_MASK_MASK;   

    for (; start_addr <= end_addr; start_addr += (1 << PAGE_MASK_SHIFT)) {
        uint64_t mask = (uint64_t)1 << ((start_addr >> PAGE_MASK_SHIFT) & PAGE_MASK_MASK);

        /* Do nothing if the pages array is empty or DMA reads/writes to/from PCI device memory addresses
           may crash the emulator. */
        cur_addr = (start_addr >> 12);
        if (cur_addr < pages_sz)
                pages[cur_addr].dirty_mask[(start_addr >> PAGE_MASK_INDEX_SHIFT) & PAGE_MASK_INDEX_MASK] |= mask;
    }
}
***** MEM_NEW.C
void
mem_write_null(uint32_t addr, uint8_t val, void *p)
{
}
*****

***** mem.c

static __inline int
mem_mapping_read_allowed(uint32_t flags, int state)
{
    switch (state & MEM_READ_MASK) {
        case MEM_READ_DISABLED:
                return 0;

        case MEM_READ_ANY:
                return 1;

        /* On external and 0 mappings without ROMCS. */
        case MEM_READ_EXTERNAL:
                return !(flags & MEM_MAPPING_INTERNAL) && !(flags & MEM_MAPPING_ROMCS);

        /* On external and 0 mappings with ROMCS. */
        case MEM_READ_ROMCS:
                return !(flags & MEM_MAPPING_INTERNAL) && (flags & MEM_MAPPING_ROMCS);

        /* On any external mappings. */
        case MEM_READ_EXTANY:
                return !(flags & MEM_MAPPING_INTERNAL);

        case MEM_READ_INTERNAL:
                return !(flags & MEM_MAPPING_EXTERNAL);

        default:
                fatal("mem_mapping_read_allowed : bad state %x\n", state);
    }

    return 0;
}
***** MEM_NEW.C

void
mem_write_nullw(uint32_t addr, uint16_t val, void *p)
{
}
*****

***** mem.c

static __inline int
mem_mapping_write_allowed(uint32_t flags, int state)
{
    switch (state & MEM_WRITE_MASK) {
        case MEM_WRITE_DISABLED:
                return 0;

        case MEM_WRITE_ANY:
                return 1;

        /* On external and 0 mappings without ROMCS. */
        case MEM_WRITE_EXTERNAL:
                return !(flags & MEM_MAPPING_INTERNAL) && !(flags & MEM_MAPPING_ROMCS);

        /* On external and 0 mappings with ROMCS. */
        case MEM_WRITE_ROMCS:
                return !(flags & MEM_MAPPING_INTERNAL) && (flags & MEM_MAPPING_ROMCS);

        /* On any external mappings. */
        case MEM_WRITE_EXTANY:
                return !(flags & MEM_MAPPING_INTERNAL);

        case MEM_WRITE_INTERNAL:
                return !(flags & MEM_MAPPING_EXTERNAL);

        default:
                fatal("mem_mapping_write_allowed : bad state %x\n", state);
    }

    return 0;
}
***** MEM_NEW.C

void
mem_write_nulll(uint32_t addr, uint32_t val, void *p)
{
}
*****

***** mem.c

static void
mem_mapping_recalc(uint64_t base, uint64_t size)
{
    mem_mapping_t *map = base_mapping.next;
    uint64_t c;

    if (! size) return;

    /* Clear out old mappings. */
    for (c = base; c < base + size; c += MEM_GRANULARITY_SIZE) {
        read_mapping[c >> MEM_GRANULARITY_BITS] = NULL;
        write_mapping[c >> MEM_GRANULARITY_BITS] = NULL;
        _mem_exec[c >> MEM_GRANULARITY_BITS] = NULL;
    }

    /* Walk mapping list. */
    while (map != NULL) {
        /*In range?*/
        if (map->enable && (uint64_t)map->base < ((uint64_t)base + (uint64_t)size) && ((uint64_t)map->base + (uint64_t)map->siz
e) > (uint64_t)base) {
                uint64_t start = (map->base < base) ? map->base : base;
                uint64_t end   = (((uint64_t)map->base + (uint64_t)map->size) < (base + size)) ? ((uint64_t)map->base + (uint64
_t)map->size) : (base + size);
                if (start < map->base)
                        start = map->base;

                for (c = start; c < end; c += MEM_GRANULARITY_SIZE) {
                        if ((map->read_b || map->read_w || map->read_l) &&
                             mem_mapping_read_allowed(map->flags, _mem_state[c >> MEM_GRANULARITY_BITS])) {
                                if (map->exec)
                                        _mem_exec[c >> MEM_GRANULARITY_BITS] = map->exec + (c - map->base);
                                else
                                        _mem_exec[c >> MEM_GRANULARITY_BITS] = NULL;
                                read_mapping[c >> MEM_GRANULARITY_BITS] = map;
                        }
                        if ((map->write_b || map->write_w || map->write_l) &&
                             mem_mapping_write_allowed(map->flags, _mem_state[c >> MEM_GRANULARITY_BITS]))
                                write_mapping[c >> MEM_GRANULARITY_BITS] = map;
                }
        }
        map = map->next;
    }

    flushmmucache_cr3();
}
***** MEM_NEW.C

void
mem_invalidate_range(uint32_t start_addr, uint32_t end_addr)
{
    uint64_t mask;
    page_t *p;

    start_addr &= ~PAGE_MASK_MASK;
    end_addr = (end_addr + PAGE_MASK_MASK) & ~PAGE_MASK_MASK;        

    for (; start_addr <= end_addr; start_addr += (1 << PAGE_MASK_SHIFT)) {
        if ((start_addr >> 12) >= pages_sz)
                continue;

        mask = (uint64_t)1 << ((start_addr >> PAGE_MASK_SHIFT) & PAGE_MASK_MASK);

        p = &pages[start_addr >> 12];

        p->dirty_mask |= mask;
        if ((p->code_present_mask & mask) && !page_in_evict_list(p))
                page_add_to_evict_list(p);
    }
}
*****

***** mem.c

void
mem_mapping_del(mem_mapping_t *map)
{
    mem_mapping_t *ptr;

    /* Disable the entry. */
    mem_mapping_disable(map);

    /* Zap it from the list. */
    for (ptr = &base_mapping; ptr->next != NULL; ptr = ptr->next) {
        if (ptr->next == map) {
                ptr->next = map->next;
                break;
        }
    }
}
***** MEM_NEW.C

static __inline int
mem_mapping_read_allowed(uint32_t flags, int state)
{
    switch (state & MEM_READ_MASK) {
        case MEM_READ_DISABLED:
                return 0;

        case MEM_READ_ANY:
                return 1;

        /* On external and 0 mappings without ROMCS. */
        case MEM_READ_EXTERNAL:
                return !(flags & MEM_MAPPING_INTERNAL) && !(flags & MEM_MAPPING_ROMCS);

        /* On external and 0 mappings with ROMCS. */
        case MEM_READ_ROMCS:
                return !(flags & MEM_MAPPING_INTERNAL) && (flags & MEM_MAPPING_ROMCS);

        /* On any external mappings. */
        case MEM_READ_EXTANY:
                return !(flags & MEM_MAPPING_INTERNAL);

        case MEM_READ_INTERNAL:
                return !(flags & MEM_MAPPING_EXTERNAL);

        default:
                fatal("mem_mapping_read_allowed : bad state %x\n", state);
    }

    return 0;
}
*****

***** mem.c

void
mem_mapping_add(mem_mapping_t *map,
                uint32_t base, 
                uint32_t size, 
                uint8_t  (*read_b)(uint32_t addr, void *p),
                uint16_t (*read_w)(uint32_t addr, void *p),
                uint32_t (*read_l)(uint32_t addr, void *p),
                void (*write_b)(uint32_t addr, uint8_t  val, void *p),
                void (*write_w)(uint32_t addr, uint16_t val, void *p),
                void (*write_l)(uint32_t addr, uint32_t val, void *p),
                uint8_t *exec,
                uint32_t fl,
                void *p)
{
    mem_mapping_t *dest = &base_mapping;

    /* Add mapping to the end of the list.*/
    while (dest->next)
        dest = dest->next;
    dest->next = map;
    map->prev = dest;

    if (size)
        map->enable  = 1;
      else
        map->enable  = 0;
    map->base    = base;
    map->size    = size;
    map->read_b  = read_b;
    map->read_w  = read_w;
    map->read_l  = read_l;
    map->write_b = write_b;
    map->write_w = write_w;
    map->write_l = write_l;
    map->exec    = exec;
    map->flags   = fl;
    map->p       = p;
    map->dev     = NULL;
    map->next    = NULL;

    mem_mapping_recalc(map->base, map->size);
}
***** MEM_NEW.C

static __inline int
mem_mapping_write_allowed(uint32_t flags, int state)
{
    switch (state & MEM_WRITE_MASK) {
        case MEM_WRITE_DISABLED:
                return 0;

        case MEM_WRITE_ANY:
                return 1;

        /* On external and 0 mappings without ROMCS. */
        case MEM_WRITE_EXTERNAL:
                return !(flags & MEM_MAPPING_INTERNAL) && !(flags & MEM_MAPPING_ROMCS);

        /* On external and 0 mappings with ROMCS. */
        case MEM_WRITE_ROMCS:
                return !(flags & MEM_MAPPING_INTERNAL) && (flags & MEM_MAPPING_ROMCS);

        /* On any external mappings. */
        case MEM_WRITE_EXTANY:
                return !(flags & MEM_MAPPING_INTERNAL);

        case MEM_WRITE_INTERNAL:
                return !(flags & MEM_MAPPING_EXTERNAL);

        default:
                fatal("mem_mapping_write_allowed : bad state %x\n", state);
    }

    return 0;
}
*****

***** mem.c

void
mem_mapping_set_handler(mem_mapping_t *map,
                        uint8_t  (*read_b)(uint32_t addr, void *p),
                        uint16_t (*read_w)(uint32_t addr, void *p),
                        uint32_t (*read_l)(uint32_t addr, void *p),
                        void (*write_b)(uint32_t addr, uint8_t  val, void *p),
                        void (*write_w)(uint32_t addr, uint16_t val, void *p),
                        void (*write_l)(uint32_t addr, uint32_t val, void *p))
{
    map->read_b  = read_b;
    map->read_w  = read_w;
    map->read_l  = read_l;
    map->write_b = write_b;
    map->write_w = write_w;
    map->write_l = write_l;

    mem_mapping_recalc(map->base, map->size);
}
***** MEM_NEW.C

static void
mem_mapping_recalc(uint64_t base, uint64_t size)
{
    mem_mapping_t *map = base_mapping.next;
    uint64_t c;

    if (! size) return;

    /* Clear out old mappings. */
    for (c = base; c < base + size; c += MEM_GRANULARITY_SIZE) {
        read_mapping[c >> MEM_GRANULARITY_BITS] = NULL;
        write_mapping[c >> MEM_GRANULARITY_BITS] = NULL;
        _mem_exec[c >> MEM_GRANULARITY_BITS] = NULL;
    }

    /* Walk mapping list. */
    while (map != NULL) {
        /*In range?*/
        if (map->enable && (uint64_t)map->base < ((uint64_t)base + (uint64_t)size) && ((uint64_t)map->base + (uint64_t)map->siz
e) > (uint64_t)base) {
                uint64_t start = (map->base < base) ? map->base : base;
                uint64_t end   = (((uint64_t)map->base + (uint64_t)map->size) < (base + size)) ? ((uint64_t)map->base + (uint64
_t)map->size) : (base + size);
                if (start < map->base)
                        start = map->base;

                for (c = start; c < end; c += MEM_GRANULARITY_SIZE) {
                        if ((map->read_b || map->read_w || map->read_l) &&
                             mem_mapping_read_allowed(map->flags, _mem_state[c >> MEM_GRANULARITY_BITS])) {
                                read_mapping[c >> MEM_GRANULARITY_BITS] = map;
                                if (map->exec)
                                        _mem_exec[c >> MEM_GRANULARITY_BITS] = map->exec + (c - map->base);
                                else
                                        _mem_exec[c >> MEM_GRANULARITY_BITS] = NULL;
                        }
                        if ((map->write_b || map->write_w || map->write_l) &&
                             mem_mapping_write_allowed(map->flags, _mem_state[c >> MEM_GRANULARITY_BITS]))
                                write_mapping[c >> MEM_GRANULARITY_BITS] = map;
                }
        }
        map = map->next;
    }

    flushmmucache_cr3();
}
*****

***** mem.c
void
mem_mapping_set_addr(mem_mapping_t *map, uint32_t base, uint32_t size)
{
    /* Remove old mapping. */
    map->enable = 0;
    mem_mapping_recalc(map->base, map->size);

    /* Set new mapping. */
    map->enable = 1;
    map->base = base;
    map->size = size;

    mem_mapping_recalc(map->base, map->size);
}
***** MEM_NEW.C
void
mem_mapping_del(mem_mapping_t *map)
{
    mem_mapping_t *ptr;

    /* Disable the entry. */
    mem_mapping_disable(map);

    /* Zap it from the list. */
    for (ptr = &base_mapping; ptr->next != NULL; ptr = ptr->next) {
        if (ptr->next == map) {
                ptr->next = map->next;
                break;
        }
    }
}
*****

***** mem.c
void
mem_mapping_set_exec(mem_mapping_t *map, uint8_t *exec)
{
    map->exec = exec;

***** MEM_NEW.C
void
mem_mapping_add(mem_mapping_t *map,
                uint32_t base, 
                uint32_t size, 
                uint8_t  (*read_b)(uint32_t addr, void *p),
                uint16_t (*read_w)(uint32_t addr, void *p),
                uint32_t (*read_l)(uint32_t addr, void *p),
                void (*write_b)(uint32_t addr, uint8_t  val, void *p),
                void (*write_w)(uint32_t addr, uint16_t val, void *p),
                void (*write_l)(uint32_t addr, uint32_t val, void *p),
                uint8_t *exec,
                uint32_t fl,
                void *p)
{
    mem_mapping_t *dest = &base_mapping;

    /* Add mapping to the end of the list.*/
    while (dest->next)
        dest = dest->next;
    dest->next = map;
    map->prev = dest;

    if (size)
        map->enable  = 1;
      else
        map->enable  = 0;
    map->base    = base;
    map->size    = size;
    map->read_b  = read_b;
    map->read_w  = read_w;
    map->read_l  = read_l;
    map->write_b = write_b;
    map->write_w = write_w;
    map->write_l = write_l;
    map->exec    = exec;
    map->flags   = fl;
    map->p       = p;
    map->dev     = NULL;
    map->next    = NULL;

*****

***** mem.c
void
mem_mapping_set_p(mem_mapping_t *map, void *p)
{
    map->p = p;
}
***** MEM_NEW.C
void
mem_mapping_set_handler(mem_mapping_t *map,
                        uint8_t  (*read_b)(uint32_t addr, void *p),
                        uint16_t (*read_w)(uint32_t addr, void *p),
                        uint32_t (*read_l)(uint32_t addr, void *p),
                        void (*write_b)(uint32_t addr, uint8_t  val, void *p),
                        void (*write_w)(uint32_t addr, uint16_t val, void *p),
                        void (*write_l)(uint32_t addr, uint32_t val, void *p))
{
    map->read_b  = read_b;
    map->read_w  = read_w;
    map->read_l  = read_l;
    map->write_b = write_b;
    map->write_w = write_w;
    map->write_l = write_l;

    mem_mapping_recalc(map->base, map->size);
}
*****

***** mem.c
void
mem_mapping_set_dev(mem_mapping_t *map, void *p)
{
    map->dev = p;
}


void
mem_mapping_disable(mem_mapping_t *map)
{
    map->enable = 0;

***** MEM_NEW.C
void
mem_mapping_set_addr(mem_mapping_t *map, uint32_t base, uint32_t size)
{
    /* Remove old mapping. */
    map->enable = 0;
    mem_mapping_recalc(map->base, map->size);

    /* Set new mapping. */
    map->enable = 1;
    map->base = base;
    map->size = size;

*****

***** mem.c
void
mem_mapping_enable(mem_mapping_t *map)
{
    map->enable = 1;

***** MEM_NEW.C
void
mem_mapping_set_exec(mem_mapping_t *map, uint8_t *exec)
{
    map->exec = exec;

*****

***** mem.c
void
mem_set_mem_state(uint32_t base, uint32_t size, int state)
{
    uint32_t c;

    for (c = 0; c < size; c += MEM_GRANULARITY_SIZE) {
        _mem_state_bak[(c + base) >> MEM_GRANULARITY_BITS] = _mem_state[(c + base) >> MEM_GRANULARITY_BITS];
        _mem_state[(c + base) >> MEM_GRANULARITY_BITS] = state;
    }

    mem_mapping_recalc(base, size);
}
***** MEM_NEW.C
void
mem_mapping_set_p(mem_mapping_t *map, void *p)
{
    map->p = p;
}
*****

***** mem.c
void
mem_restore_mem_state(uint32_t base, uint32_t size)
{
    uint32_t c;

    for (c = 0; c < size; c += MEM_GRANULARITY_SIZE)
        _mem_state[(c + base) >> MEM_GRANULARITY_BITS] = _mem_state_bak[(c + base) >> MEM_GRANULARITY_BITS];

    mem_mapping_recalc(base, size);
}
***** MEM_NEW.C
void
mem_mapping_set_dev(mem_mapping_t *map, void *p)
{
    map->dev = p;
}
*****

***** mem.c
void
mem_add_bios(void)
{
    if (biosmask > 0x1ffff) {
        /* 256k+ BIOS'es only have low mappings at E0000-FFFFF. */
        mem_mapping_add(&bios_mapping, 0xe0000, 0x20000,
                        mem_read_bios,mem_read_biosw,mem_read_biosl,
                        mem_write_null,mem_write_nullw,mem_write_nulll,
                        &rom[0x20000], MEM_MAPPING_EXTERNAL|MEM_MAPPING_ROM|MEM_MAPPING_ROMCS, 0);

        mem_set_mem_state(0x0e0000, 0x20000,
                          MEM_READ_ROMCS | MEM_WRITE_ROMCS);
    } else {
        mem_mapping_add(&bios_mapping, biosaddr, biosmask + 1,
                        mem_read_bios,mem_read_biosw,mem_read_biosl,
                        mem_write_null,mem_write_nullw,mem_write_nulll,
                        rom, MEM_MAPPING_EXTERNAL|MEM_MAPPING_ROM|MEM_MAPPING_ROMCS, 0);

        mem_set_mem_state(biosaddr, biosmask + 1,
                          MEM_READ_ROMCS | MEM_WRITE_ROMCS);
    }
***** MEM_NEW.C
void
mem_mapping_disable(mem_mapping_t *map)
{
    map->enable = 0;

    mem_mapping_recalc(map->base, map->size);
}


void
mem_mapping_enable(mem_mapping_t *map)
{
    map->enable = 1;

    mem_mapping_recalc(map->base, map->size);
}


void
mem_set_mem_state(uint32_t base, uint32_t size, int state)
{
    uint32_t c;

    for (c = 0; c < size; c += MEM_GRANULARITY_SIZE) {
        _mem_state_bak[(c + base) >> MEM_GRANULARITY_BITS] = _mem_state[(c + base) >> MEM_GRANULARITY_BITS];
        _mem_state[(c + base) >> MEM_GRANULARITY_BITS] = state;
    }
*****

***** mem.c

    if (AT) {
        mem_mapping_add(&bios_high_mapping, biosaddr | (cpu_16bitbus ? 0x00f00000 : 0xfff00000), biosmask + 1,
                        mem_read_bios,mem_read_biosw,mem_read_biosl,
                        mem_write_null,mem_write_nullw,mem_write_nulll,
                        rom, MEM_MAPPING_EXTERNAL|MEM_MAPPING_ROM|MEM_MAPPING_ROMCS, 0);

        mem_set_mem_state(biosaddr | (cpu_16bitbus ? 0x00f00000 : 0xfff00000), biosmask + 1,
                          MEM_READ_ROMCS | MEM_WRITE_ROMCS);
    }
}
***** MEM_NEW.C

    mem_mapping_recalc(base, size);
}
*****

***** mem.c
void
mem_a20_init(void)
{
    if (AT) {
        rammask = cpu_16bitbus ? 0xefffff : 0xffefffff;
        flushmmucache();
        mem_a20_state = mem_a20_key | mem_a20_alt;
    } else {
        rammask = 0xfffff;
        flushmmucache();
        mem_a20_key = mem_a20_alt = mem_a20_state = 0;
    }
}
***** MEM_NEW.C
void
mem_restore_mem_state(uint32_t base, uint32_t size)
{
    uint32_t c;

    for (c = 0; c < size; c += MEM_GRANULARITY_SIZE)
        _mem_state[(c + base) >> MEM_GRANULARITY_BITS] = _mem_state_bak[(c + base) >> MEM_GRANULARITY_BITS];

    mem_mapping_recalc(base, size);
}
*****

***** mem.c

/* Reset the memory state. */
void
mem_reset(void)
{
    uint32_t c, m;

    m = 1024UL * mem_size;
    if (ram != NULL) {
        free(ram);
        ram = NULL;
    }
    ram = (uint8_t *)malloc(m);         /* allocate and clear the RAM block */
    memset(ram, 0x00, m);

    /*
     * Allocate the page table based on how much RAM we have.
     * We re-allocate the table on each (hard) reset, as the
     * memory amount could have changed.
     */
    if (AT) {
        if (cpu_16bitbus) {
                /* 80186/286; maximum address space is 16MB. */
                m = 4096;
        } else {
                /* 80386+; maximum address space is 4GB. */
                m = (mem_size + 384) >> 2;
                if ((m << 2) < (mem_size + 384))
                        m++;
                if (m < 4096)
                        m = 4096;
        }
    } else {
        /* 8088/86; maximum address space is 1MB. */
        m = 256;
    }
***** MEM_NEW.C

void
mem_add_bios(void)
{
    if (biosmask > 0x1ffff) {
        /* 256k+ BIOS'es only have low mappings at E0000-FFFFF. */
        mem_mapping_add(&bios_mapping, 0xe0000, 0x20000,
                        mem_read_bios,mem_read_biosw,mem_read_biosl,
                        mem_write_null,mem_write_nullw,mem_write_nulll,
                        &rom[0x20000], MEM_MAPPING_EXTERNAL|MEM_MAPPING_ROM|MEM_MAPPING_ROMCS, 0);

        mem_set_mem_state(0x0e0000, 0x20000,
                          MEM_READ_ROMCS | MEM_WRITE_ROMCS);
    } else {
        mem_mapping_add(&bios_mapping, biosaddr, biosmask + 1,
                        mem_read_bios,mem_read_biosw,mem_read_biosl,
                        mem_write_null,mem_write_nullw,mem_write_nulll,
                        rom, MEM_MAPPING_EXTERNAL|MEM_MAPPING_ROM|MEM_MAPPING_ROMCS, 0);

        mem_set_mem_state(biosaddr, biosmask + 1,
                          MEM_READ_ROMCS | MEM_WRITE_ROMCS);
    }
*****

***** mem.c

    /*
     * Allocate and initialize the (new) page table.
     * We only do this if the size of the page table has changed.
     */
#if DYNAMIC_TABLES
mem_log("MEM: reset: previous pages=%08lx, pages_sz=%i\n", pages, pages_sz);
#endif
    if (pages_sz != m) {
        pages_sz = m;
        if (pages) {
                free(pages);
                pages = NULL;
        }
        pages = (page_t *)malloc(m*sizeof(page_t));
#if DYNAMIC_TABLES
mem_log("MEM: reset: new pages=%08lx, pages_sz=%i\n", pages, pages_sz);
#endif

#if DYNAMIC_TABLES
        /* Allocate the (new) lookup tables. */
        if (page_lookup != NULL) free(page_lookup);
        page_lookup = (page_t **)malloc(pages_sz*sizeof(page_t *));

        if (readlookup2 != NULL) free(readlookup2);
        readlookup2  = malloc(pages_sz*sizeof(uintptr_t));

        if (writelookup2 != NULL) free(writelookup2);
        writelookup2 = malloc(pages_sz*sizeof(uintptr_t));

#endif
    }

#if DYNAMIC_TABLES
    memset(page_lookup, 0x00, pages_sz * sizeof(page_t *));
#else
    memset(page_lookup, 0x00, (1 << 20) * sizeof(page_t *));
#endif

    memset(pages, 0x00, pages_sz*sizeof(page_t));

***** MEM_NEW.C

    if (AT) {
        mem_mapping_add(&bios_high_mapping, biosaddr | (cpu_16bitbus ? 0x00f00000 : 0xfff00000), biosmask + 1,
                        mem_read_bios,mem_read_biosw,mem_read_biosl,
                        mem_write_null,mem_write_nullw,mem_write_nulll,
                        rom, MEM_MAPPING_EXTERNAL|MEM_MAPPING_ROM|MEM_MAPPING_ROMCS, 0);

        mem_set_mem_state(biosaddr | (cpu_16bitbus ? 0x00f00000 : 0xfff00000), biosmask + 1,
                          MEM_READ_ROMCS | MEM_WRITE_ROMCS);
    }
}

*****

***** mem.c

    for (c = 0; c < pages_sz; c++) {
        pages[c].mem = &ram[c << 12];
        pages[c].write_b = mem_write_ramb_page;
        pages[c].write_w = mem_write_ramw_page;
        pages[c].write_l = mem_write_raml_page;
    }
***** MEM_NEW.C

void
mem_a20_init(void)
{
    if (AT) {
        rammask = cpu_16bitbus ? 0xefffff : 0xffefffff;
        flushmmucache();
        mem_a20_state = mem_a20_key | mem_a20_alt;
    } else {
        rammask = 0xfffff;
        flushmmucache();
        mem_a20_key = mem_a20_alt = mem_a20_state = 0;
    }
}


/* Reset the memory state. */
void
mem_reset(void)
{
    uint32_t c, m;

    m = 1024UL * mem_size;
    if (ram != NULL) {
        free(ram);
        ram = NULL;
    }
    ram = (uint8_t *)malloc(m);         /* allocate and clear the RAM block */
    memset(ram, 0x00, m);

    /*
     * Allocate the page table based on how much RAM we have.
     * We re-allocate the table on each (hard) reset, as the
     * memory amount could have changed.
     */
    if (AT) {
        if (cpu_16bitbus) {
                /* 80186/286; maximum address space is 16MB. */
                m = 4096;
        } else {
                /* 80386+; maximum address space is 4GB. */
                m = (mem_size + 384) >> 2;
                if ((m << 2) < (mem_size + 384))
                        m++;
                if (m < 4096)
                        m = 4096;
        }
    } else {
        /* 8088/86; maximum address space is 1MB. */
        m = 256;
    }
*****

***** mem.c

    memset(_mem_exec,    0x00, sizeof(_mem_exec));

    memset(&base_mapping, 0x00, sizeof(base_mapping));

    memset(_mem_state, 0x00, sizeof(_mem_state));
    memset(_mem_state_bak, 0x00, sizeof(_mem_state_bak));

    mem_set_mem_state(0x000000, (mem_size > 640) ? 0xa0000 : mem_size * 1024,
                      MEM_READ_INTERNAL | MEM_WRITE_INTERNAL);
    mem_set_mem_state(0x0c0000, 0x40000,
                      MEM_READ_EXTERNAL | MEM_WRITE_EXTERNAL);

    mem_mapping_add(&ram_low_mapping, 0x00000,
                    (mem_size > 640) ? 0xa0000 : mem_size * 1024,
                    mem_read_ram,mem_read_ramw,mem_read_raml,
                    mem_write_ram,mem_write_ramw,mem_write_raml,
                    ram, MEM_MAPPING_INTERNAL, NULL);

    if (mem_size > 1024) {
        if (cpu_16bitbus && mem_size > 16256) {
                mem_set_mem_state(0x100000, (16256 - 1024) * 1024,
                                  MEM_READ_INTERNAL | MEM_WRITE_INTERNAL);
                mem_mapping_add(&ram_high_mapping, 0x100000,
                                ((16256 - 1024) * 1024),
                                mem_read_ram,mem_read_ramw,mem_read_raml,
                                mem_write_ram,mem_write_ramw,mem_write_raml,
                                ram + 0x100000, MEM_MAPPING_INTERNAL, NULL);
        } else {
                mem_set_mem_state(0x100000, (mem_size - 1024) * 1024,
                                  MEM_READ_INTERNAL | MEM_WRITE_INTERNAL);
                mem_mapping_add(&ram_high_mapping, 0x100000,
                                ((mem_size - 1024) * 1024),
                                mem_read_ram,mem_read_ramw,mem_read_raml,
                                mem_write_ram,mem_write_ramw,mem_write_raml,
                                ram + 0x100000, MEM_MAPPING_INTERNAL, NULL);
        }
    }
***** MEM_NEW.C

    /*
     * Allocate and initialize the (new) page table.
     * We only do this if the size of the page table has changed.
     */
#if DYNAMIC_TABLES
mem_log("MEM: reset: previous pages=%08lx, pages_sz=%i\n", pages, pages_sz);
#endif
    if (pages_sz != m) {
        pages_sz = m;
        if (pages) {
                free(pages);
                pages = NULL;
        }
        pages = (page_t *)malloc(m*sizeof(page_t));
#if DYNAMIC_TABLES
mem_log("MEM: reset: new pages=%08lx, pages_sz=%i\n", pages, pages_sz);
#endif

#if DYNAMIC_TABLES
        /* Allocate the (new) lookup tables. */
        if (page_lookup != NULL) free(page_lookup);
        page_lookup = (page_t **)malloc(pages_sz*sizeof(page_t *));

        if (readlookup2 != NULL) free(readlookup2);
        readlookup2  = malloc(pages_sz*sizeof(uintptr_t));

        if (writelookup2 != NULL) free(writelookup2);
        writelookup2 = malloc(pages_sz*sizeof(uintptr_t));

#endif
    }
*****

***** mem.c

    if (mem_size > 768)
        mem_mapping_add(&ram_mid_mapping, 0xc0000, 0x40000,
                        mem_read_ram,mem_read_ramw,mem_read_raml,
                        mem_write_ram,mem_write_ramw,mem_write_raml,
                        ram + 0xc0000, MEM_MAPPING_INTERNAL, NULL);
                        
    mem_mapping_add(&ram_remapped_mapping, mem_size * 1024, 256 * 1024,
                    mem_read_remapped,mem_read_remappedw,mem_read_remappedl,
                    mem_write_remapped,mem_write_remappedw,mem_write_remappedl,
                    ram + 0xa0000, MEM_MAPPING_INTERNAL, NULL);
    mem_mapping_disable(&ram_remapped_mapping);                 
                        
    mem_a20_init();
}

***** MEM_NEW.C

#if DYNAMIC_TABLES
    memset(page_lookup, 0x00, pages_sz * sizeof(page_t *));
#else
    memset(page_lookup, 0x00, (1 << 20) * sizeof(page_t *));
#endif

    memset(pages, 0x00, pages_sz*sizeof(page_t));

*****

***** mem.c

void
mem_init(void)
{
    /* Perform a one-time init. */
    ram = rom = NULL;
    pages = NULL;
#if DYNAMIC_TABLES
    page_lookup = NULL;
    readlookup2 = NULL;
    writelookup2 = NULL;

#else
    /* Allocate the lookup tables. */
    page_lookup = (page_t **)malloc((1<<20)*sizeof(page_t *));

    readlookup2  = malloc((1<<20)*sizeof(uintptr_t));

    writelookup2 = malloc((1<<20)*sizeof(uintptr_t));
#endif

#if FIXME
    memset(ff_array, 0xff, sizeof(ff_array));
#endif

    /* Reset the memory state. */
    mem_reset();
}


void
mem_remap_top(int kb)
{
    int c;
    uint32_t start = (mem_size >= 1024) ? mem_size : 1024;
    int size = mem_size - 640;

    mem_log("MEM: remapping top %iKB (mem=%i)\n", kb, mem_size);
    if (mem_size <= 640) return;

    if (kb == 0) {
        /* Called to disable the mapping. */
        mem_mapping_disable(&ram_remapped_mapping);

        return;
     }  
        
    if (size > kb)
        size = kb;

    for (c = ((start * 1024) >> 12); c < (((start + size) * 1024) >> 12); c++) {
        pages[c].mem = &ram[0xA0000 + ((c - ((start * 1024) >> 12)) << 12)];
        pages[c].write_b = mem_write_ramb_page;
***** MEM_NEW.C

    if (byte_dirty_mask) {
        free(byte_dirty_mask);
        byte_dirty_mask = NULL;
    }
    byte_dirty_mask = malloc((mem_size * 1024) / 8);
    memset(byte_dirty_mask, 0, (mem_size * 1024) / 8);

    if (byte_code_present_mask) {
        free(byte_code_present_mask);
        byte_code_present_mask = NULL;
    }
    byte_code_present_mask = malloc((mem_size * 1024) / 8);
    memset(byte_code_present_mask, 0, (mem_size * 1024) / 8);

    for (c = 0; c < pages_sz; c++) {
        pages[c].mem = &ram[c << 12];
        pages[c].write_b = mem_write_ramb_page;
*****

***** mem.c
        pages[c].write_l = mem_write_raml_page;
    }
***** MEM_NEW.C
        pages[c].write_l = mem_write_raml_page;
        pages[c].evict_prev = EVICT_NOT_IN_LIST;
        pages[c].byte_dirty_mask = &byte_dirty_mask[c * 64];
        pages[c].byte_code_present_mask = &byte_code_present_mask[c * 64];
    }
*****

***** mem.c

    mem_set_mem_state(start * 1024, size * 1024,
                      MEM_READ_INTERNAL | MEM_WRITE_INTERNAL);
    mem_mapping_set_addr(&ram_remapped_mapping, start * 1024, size * 1024);
    mem_mapping_set_exec(&ram_remapped_mapping, ram + (start * 1024));

    flushmmucache();
}

void
mem_reset_page_blocks(void)
{
    uint32_t c;

    if (pages == NULL) return;

    for (c = 0; c < pages_sz; c++) {
        pages[c].write_b = mem_write_ramb_page;
        pages[c].write_w = mem_write_ramw_page;
        pages[c].write_l = mem_write_raml_page;
        pages[c].block[0] = pages[c].block[1] = pages[c].block[2] = pages[c].block[3] = NULL;
        pages[c].block_2[0] = pages[c].block_2[1] = pages[c].block_2[2] = pages[c].block_2[3] = NULL;
    }
}


void
mem_a20_recalc(void)
{
    int state;

    if (! AT) {
        rammask = 0xfffff;
        flushmmucache();
        mem_a20_key = mem_a20_alt = mem_a20_state = 0;

        return;
    }
***** MEM_NEW.C

    memset(_mem_exec,    0x00, sizeof(_mem_exec));

    memset(&base_mapping, 0x00, sizeof(base_mapping));

    memset(_mem_state, 0x00, sizeof(_mem_state));
    memset(_mem_state_bak, 0x00, sizeof(_mem_state));

    mem_set_mem_state(0x000000, (mem_size > 640) ? 0xa0000 : mem_size * 1024,
                      MEM_READ_INTERNAL | MEM_WRITE_INTERNAL);
    mem_set_mem_state(0x0c0000, 0x40000,
                      MEM_READ_EXTERNAL | MEM_WRITE_EXTERNAL);

    mem_mapping_add(&ram_low_mapping, 0x00000,
                    (mem_size > 640) ? 0xa0000 : mem_size * 1024,
                    mem_read_ram,mem_read_ramw,mem_read_raml,
                    mem_write_ram,mem_write_ramw,mem_write_raml,
                    ram, MEM_MAPPING_INTERNAL, NULL);

    if (mem_size > 1024) {
        if (cpu_16bitbus && mem_size > 16256) {
                mem_set_mem_state(0x100000, (16256 - 1024) * 1024,
                                  MEM_READ_INTERNAL | MEM_WRITE_INTERNAL);
                mem_mapping_add(&ram_high_mapping, 0x100000,
                                ((16256 - 1024) * 1024),
                                mem_read_ram,mem_read_ramw,mem_read_raml,
                                mem_write_ram,mem_write_ramw,mem_write_raml,
                                ram + 0x100000, MEM_MAPPING_INTERNAL, NULL);
        } else {
                mem_set_mem_state(0x100000, (mem_size - 1024) * 1024,
                                  MEM_READ_INTERNAL | MEM_WRITE_INTERNAL);
                mem_mapping_add(&ram_high_mapping, 0x100000,
                                ((mem_size - 1024) * 1024),
                                mem_read_ram,mem_read_ramw,mem_read_raml,
                                mem_write_ram,mem_write_ramw,mem_write_raml,
                                ram + 0x100000, MEM_MAPPING_INTERNAL, NULL);
        }
    }
*****

***** mem.c

    state = mem_a20_key | mem_a20_alt;
    if (state && !mem_a20_state) {
        rammask = (AT && cpu_16bitbus) ? 0xffffff : 0xffffffff;
        flushmmucache();
    } else if (!state && mem_a20_state) {
        rammask = (AT && cpu_16bitbus) ? 0xefffff : 0xffefffff;
        flushmmucache();
    }

    mem_a20_state = state;
}
***** MEM_NEW.C

    if (mem_size > 768)
        mem_mapping_add(&ram_mid_mapping, 0xc0000, 0x40000,
                        mem_read_ram,mem_read_ramw,mem_read_raml,
                        mem_write_ram,mem_write_ramw,mem_write_raml,
                        ram + 0xc0000, MEM_MAPPING_INTERNAL, NULL);
                        
    mem_mapping_add(&ram_remapped_mapping, mem_size * 1024, 256 * 1024,
                    mem_read_remapped,mem_read_remappedw,mem_read_remappedl,
                    mem_write_remapped,mem_write_remappedw,mem_write_remappedl,
                    ram + 0xa0000, MEM_MAPPING_INTERNAL, NULL);
    mem_mapping_disable(&ram_remapped_mapping);                 
                        
    mem_a20_init();

    purgable_page_list_head = 0;
    purgeable_page_count = 0;
}
*****

Resync Failed.  Files are too different.
***** mem.c
***** MEM_NEW.C


void
mem_init(void)
{
    /* Perform a one-time init. */
    ram = rom = NULL;
    pages = NULL;
#if DYNAMIC_TABLES
    page_lookup = NULL;
    readlookup2 = NULL;
    writelookup2 = NULL;

#else
    /* Allocate the lookup tables. */
    page_lookup = (page_t **)malloc((1<<20)*sizeof(page_t *));

    readlookup2  = malloc((1<<20)*sizeof(uintptr_t));

    writelookup2 = malloc((1<<20)*sizeof(uintptr_t));
#endif

#if FIXME
    memset(ff_array, 0xff, sizeof(ff_array));
#endif

    /* Reset the memory state. */
    mem_reset();
}


void
mem_remap_top(int kb)
{
    int c;
    uint32_t start = (mem_size >= 1024) ? mem_size : 1024;
    int offset, size = mem_size - 640;

    mem_log("MEM: remapping top %iKB (mem=%i)\n", kb, mem_size);
    if (mem_size <= 640) return;

    if (kb == 0) {
        /* Called to disable the mapping. */
        mem_mapping_disable(&ram_remapped_mapping);

        return;
     }  
        
    if (size > kb)
        size = kb;

    for (c = ((start * 1024) >> 12); c < (((start + size) * 1024) >> 12); c++) {
        offset = c - ((start * 1024) >> 12);
        pages[c].mem = &ram[0xA0000 + (offset << 12)];
        pages[c].write_b = mem_write_ramb_page;
        pages[c].write_w = mem_write_ramw_page;
        pages[c].write_l = mem_write_raml_page;
        pages[c].evict_prev = EVICT_NOT_IN_LIST;
        pages[c].byte_dirty_mask = &byte_dirty_mask[offset * 64];
        pages[c].byte_code_present_mask = &byte_code_present_mask[offset * 64];
    }

    mem_set_mem_state(start * 1024, size * 1024,
                      MEM_READ_INTERNAL | MEM_WRITE_INTERNAL);
    mem_mapping_set_addr(&ram_remapped_mapping, start * 1024, size * 1024);
    mem_mapping_set_exec(&ram_remapped_mapping, ram + (start * 1024));

    flushmmucache();
}

void
mem_reset_page_blocks(void)
{
    uint32_t c;

    if (pages == NULL) return;

    for (c = 0; c < pages_sz; c++) {
        pages[c].write_b = mem_write_ramb_page;
        pages[c].write_w = mem_write_ramw_page;
        pages[c].write_l = mem_write_raml_page;
        pages[c].block = BLOCK_INVALID;
        pages[c].block_2 = BLOCK_INVALID;
    }
}


void
mem_a20_recalc(void)
{
    int state;

    if (! AT) {
        rammask = 0xfffff;
        flushmmucache();
        mem_a20_key = mem_a20_alt = mem_a20_state = 0;

        return;
    }

*****

